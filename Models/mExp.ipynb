{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于引用的专利未来影响力研究"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "DATA = pd.read_csv(\"../Data/GT36.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data.head()\n",
    "# Data[Data.isnull().values == True]\n",
    "# DATA = DATA.sort_values(by=['ISD'])\n",
    "\n",
    "# eval(DATA['b_cits'][0])\n",
    "\n",
    "pn_to_id = {}\n",
    "\n",
    "for item in DATA.values:\n",
    "    pn_to_id[item[1]] = item[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GNN Representation\n",
    "# 去掉PGPUB Document，eg: 2014/0240120\n",
    "\n",
    "now = datetime.strptime(\"2022-06-21\", \"%Y-%M-%d\").year\n",
    "pn_ls = [item[1] for item in DATA.values]\n",
    "\n",
    "n_nodes = len(DATA)\n",
    "node_dim = 2        # CPC, IPC\n",
    "\n",
    "\n",
    "Nodes_x = []        # CPC, IPC\n",
    "Nodes_y = []        # label\n",
    "Edges = []          # conectivity weights\n",
    "Adj_Ls = []         # conectivity\n",
    "\n",
    "for i in range(len(DATA)):\n",
    "    pn = DATA['PN'][i]\n",
    "    ref = DATA['REF'][i]\n",
    "    b_cits = eval(DATA['b_cits'][i])\n",
    "    isd = DATA['ISD'][i]\n",
    "\n",
    "    # x\n",
    "    node = [DATA['CPC'][i], DATA['IPC'][i]]\n",
    "    Nodes_x.append(node)\n",
    "\n",
    "    # y\n",
    "    years = now - datetime.strptime(isd, \"%Y-%M-%d\").year\n",
    "    score = ref/years       # Optimize it with python lambda\n",
    "    if score > 1:\n",
    "        node_y = 1          # positive\n",
    "    else:\n",
    "        node_y = 0          # negative\n",
    "    Nodes_y.append(node_y)\n",
    "\n",
    "    # conectivity\n",
    "    if b_cits[0] == 'NULL' or b_cits[0] == '':\n",
    "        continue\n",
    "    for cp in b_cits:\n",
    "\n",
    "        # 注意：cp 必须是已知节点，即在Nodes中 \n",
    "        if cp.find('/') == -1:\n",
    "            try:\n",
    "                if int(cp) in pn_ls:\n",
    "                    pn_id = pn_to_id[pn]\n",
    "                    cp_id = pn_to_id[int(cp)]\n",
    "                    Adj_Ls.append([pn_id, cp_id])\n",
    "                    duration = (pn - int(cp))/1e7\n",
    "                    Edges.append(duration)\n",
    "\n",
    "            except Exception as ex:\n",
    "                pass\n",
    "                # print(\"{}采集出错，出错原因：{}\".format(pn, ex))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(Adj_Ls), len(Nodes_x))\n",
    "# 687 564\n",
    "\n",
    "# Adj_Ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_nodes, num_node_features\n",
    "x = torch.tensor(Nodes_x, dtype=torch.float)\n",
    "\n",
    "# num_nodes, 1\n",
    "y = torch.tensor(Nodes_y, dtype=torch.long)\n",
    "\n",
    "# 2, num_edges\n",
    "edge_index = torch.tensor(Adj_Ls, dtype=torch.long)\n",
    "\n",
    "# num_edges, num_edge_features\n",
    "edge_attr = torch.tensor(Edges, dtype=torch.float)\n",
    "\n",
    "# train-test split\n",
    "train_ls = [True]*300 + [False]*264\n",
    "train_mask = torch.tensor(train_ls, dtype=bool)\n",
    "test_ls = [False]*300 + [True]*264\n",
    "test_mask = torch.tensor(test_ls, dtype=bool)\n",
    "\n",
    "\n",
    "data = Data(x=x, y=y, edge_index = edge_index.t().contiguous(), edge_attr=edge_attr, train_mask = train_mask, test_mask=test_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 564\n",
      "Number of edges: 687\n",
      "Number of node features: 2\n",
      "Number of node features: 2\n",
      "Number of edge features: 1\n",
      "Average node degree: 1.22\n",
      "Number of training nodes: 300\n",
      "Training node label rate: 0.53\n",
      "Contains isolated nodes: True\n",
      "Contains self-loops: False\n",
      "Is undirected: False\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of nodes: {data.num_nodes}') # 节点数量\n",
    "print(f'Number of edges: {data.num_edges}') # 边数量\n",
    "print(f'Number of node features: {data.num_node_features}') # 节点属性的维度\n",
    "print(f'Number of node features: {data.num_features}') # 同样是节点属性的维度\n",
    "print(f'Number of edge features: {data.num_edge_features}') # 边属性的维度\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}') # 平均节点度\n",
    "# print(f'if edge indices are ordered and do not contain duplicate entries.: {data.is_coalesced()}') # 是否边是有序的同时不含有重复的边\n",
    "print(f'Number of training nodes: {data.train_mask.sum()}') # 用作训练集的节点\n",
    "print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}') # 用作训练集的节点的数量\n",
    "print(f'Contains isolated nodes: {data.has_isolated_nodes()}') # 此图是否包含孤立的节点\n",
    "print(f'Contains self-loops: {data.has_self_loops()}')  # 此图是否包含自环的边\n",
    "print(f'Is undirected: {data.is_undirected()}')  # 此图是否是无向图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.is_coalesced()\n",
    "# 为何会有assertion error?\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(2, 16)\n",
    "        self.conv2 = GCNConv(16, 2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN().to(device)\n",
    "data = data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4432\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "pred = model(data).argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('DeepLearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1236240fd2af58f76b228ac445ebf0358975f22780cbaaa79de7b2468153940c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
